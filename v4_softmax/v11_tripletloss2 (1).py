# -*- coding: utf-8 -*-
"""V11_tripletloss2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oeG7_KGvdbKlXIDIiNr-qD8UBc3lfntO
"""

# Commented out IPython magic to ensure Python compatibility.
# %%
# %tensorflow_version 2.x

import os

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
from datetime import datetime
import time
import baseconf as bcf
import matplotlib.pyplot as plt

OUTPUT_DIMS=3
def downsample(filters, size, strides=2,apply_batchnorm=False,apply_pool=True):
    initializer = tf.random_normal_initializer(0., 0.02)
    result = tf.keras.Sequential()
    result.add(
        layers.Conv2D(filters, size, strides=strides, padding='same',
                               kernel_initializer=initializer, use_bias=False))
  
    if apply_batchnorm:
      result.add(layers.BatchNormalization())
  
    result.add(layers.ReLU())

    if apply_pool:
      result.add(layers.MaxPooling2D())

    return result


def make_discriminator_model():
    initializer = tf.random_normal_initializer(0., 0.02)
    
    inp = layers.Input(shape=[128, 128, 3], name='input_image')
    #tar = layers.Input(shape=[128, 128, 3], name='target_image')
  
    #x = layers.concatenate([inp, tar]) # (bs, 128, 128, channels*2)
  
    x = downsample(64, 4, 1,True)(inp) 
    x = downsample(128, 4,2)(x) 
    x = downsample(256, 4,2)(x)
    x = downsample(512, 4,1,False,False)(x)
    x = downsample(512, 4,2,False,False)(x)
    x = layers.GlobalAvgPool2D()(x)
    #x = layers.Dropout(0.2)(x)
    #x = layers.Flatten()(x)
    #x = layers.Dense(1024,activation='relu',kernel_initializer=initializer)(x)
    #x = layers.BatchNormalization()(x)
    x = layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x) # L2 normalize embeddings
    last = layers.Dense(OUTPUT_DIMS,activation='sigmoid',kernel_initializer=initializer)(x)
  
    return tf.keras.Model(inputs=inp, outputs=last)

discriminator = make_discriminator_model()
discriminator.summary()

###################HParams##############################
BATCH_SIZE=8
noise_dim=512
base_learning_rate=0.01
save_interval=5
tf.random.set_seed(0)
#tb callback
run_logdir = "/content/drive/My Drive/ugb"
version = "/v11"
generator_optimizer = tf.keras.optimizers.SGD(base_learning_rate,0.3)
discriminator_optimizer = tf.keras.optimizers.SGD(base_learning_rate,0.3)
# lr callback
def lr_scheduler(epoch):
  learning_rate = base_learning_rate
  if epoch > 10:
    learning_rate =base_learning_rate/2
  if epoch > 20:
    learning_rate = base_learning_rate/10
  if epoch > 40:
    learning_rate = base_learning_rate * tf.math.exp(0.1 * (10 - epoch))
  #for tensorboard
  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)
  tf.print("**Current Learning_rate: ",learning_rate)
  return learning_rate

LAMBDA = 100

# 该方法返回计算交叉熵损失的辅助函数
loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)

N = OUTPUT_DIMS
beta = N
epsilon = 1e-8

def discriminator_loss(anchor_out,target_out,noise_out):
  """
  lossless triplet
  改进：https://towardsdatascience.com/lossless-triplet-loss-7e932f990b24
  N是输出dim
  原文有错误，输出的是 loss = neg_dist + pos_dist， shape(batch,)

  Implementation of the triplet loss function
    
    Arguments:
    N  --  The number of dimension 
    beta -- The scaling factor, N is recommended
    epsilon -- The Epsilon value to prevent ln(0)
    
    
    Returns:
    loss -- real number, value of the loss
  """
  pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor_out,target_out)),1)
  neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor_out,noise_out)),1)

  pos_dist = -tf.math.log(-tf.divide((pos_dist),beta)+1+epsilon)
  neg_dist = -tf.math.log(-tf.divide((N-neg_dist),beta)+1+epsilon)
    
  # compute loss
  loss = tf.reduce_mean(neg_dist + pos_dist)

  return loss

# def generator_loss( disc_generated_output, gen_output, target):
#   gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)

#   # mean absolute error
#   l1_loss = tf.reduce_mean(tf.abs(target - gen_output))
#   total_gen_loss = gan_loss + (LAMBDA * l1_loss)

#   return total_gen_loss, gan_loss, l1_loss


# checkpoint and fitlog
checkpoint = tf.train.Checkpoint(discriminator=discriminator)
ckpt_manager = tf.train.CheckpointManager(checkpoint, run_logdir+version, max_to_keep=3)

fit_log = os.path.join(run_logdir+version+"_fit",datetime.now().strftime("%Y%m%d-%H%M%S"))
summary_writer = tf.summary.create_file_writer(fit_log)

# single train step
@tf.function
def train_step(anchor,target,noise,epoch):
  
  with tf.GradientTape() as disc_tape:
    anchor_output = discriminator(anchor, training=True)
    target_output = discriminator(target, training=True)
    noise_output = discriminator(noise, training=True)

    disc_loss = discriminator_loss(anchor_output,target_output,noise_output)

  discriminator_gradients = disc_tape.gradient(disc_loss,
                                               discriminator.trainable_variables)
  
  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,
                                              discriminator.trainable_variables))

  with summary_writer.as_default():
    tf.summary.scalar('disc_loss', disc_loss, step=epoch)
  return disc_loss



mse = tf.keras.losses.MeanSquaredError()
def eveluator(anchor,target,noise,y_true):
  anchor_out = discriminator(anchor, training=False)
  target_out = discriminator(target, training=False)
  noise_out = discriminator(noise, training=False)


  pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor_out,target_out)),1)
  pos_dist = tf.divide(pos_dist,N)
  neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor_out,noise_out)),1)
  neg_dist = tf.divide(neg_dist,N)

  p_loss = mse(tf.zeros_like(pos_dist),pos_dist)
  n_loss = mse(tf.ones_like(neg_dist),neg_dist)

  #cross val
  y_t = y_true[::-1,...]
  mask = tf.not_equal(y_t,y_true)
  #tf.print("mask: ",mask,y_t,y_true)
  pp_dist = tf.reduce_sum(tf.square(tf.subtract(anchor_out,target_out[::-1,...])),1)
  pp_dist = tf.divide(pp_dist,N)
  pp_loss = mse(mask,pp_dist)

  print("P_loss: %.4f, N_loss: %.4f, pp_loss: %.4f" % (p_loss,n_loss,pp_loss))

  return p_loss,n_loss,pp_loss

def train(X_train,epochs,init_epoch=1,steps_per_epoch=100,val_steps=10):
  """
  X_train - ds: 包含目标图片，变换过的图片，标签
  """
  checkpoint.restore(ckpt_manager.latest_checkpoint)
  if ckpt_manager.latest_checkpoint:
    print("Restored from {}".format(ckpt_manager.latest_checkpoint))
  else:
    print("Initializing from scratch.")
  
  print("Fire to Train....")
  for epoch in range(init_epoch,epochs+1):
    
    start = time.time()

    print("Testing....")
    # 每个EPOCH测试一次
    val_losses = []
    for (anchor,target,y),(noise,_) in X_train.take(1):
      eveluator(anchor,target,noise,y)
      

    #train start
    discriminator_optimizer = tf.keras.optimizers.SGD(lr_scheduler(epoch))

    for step in range(1,steps_per_epoch+1):
      for (anchor,target,yt),(noise,_) in X_train.take(1):
        #把不同标签的图片加入计算，这本来应该在DS中做
        yt_r = yt[::-1,...]
        target_r = target[::-1,...]
        mask = tf.not_equal(yt_r,yt)

        target_not_equal = target_r[mask == True]
        anchor_not_equal = anchor[mask == True]
        target_t = target[mask == True] #equal to anchor_not_equal
        
        anchor = tf.concat([anchor,anchor_not_equal[:BATCH_SIZE//2]],0)
        target = tf.concat([target,target_t[:BATCH_SIZE//2]],0)
        noise = tf.concat([noise,target_not_equal[:BATCH_SIZE//2]],0)

        disc_loss = train_step(anchor,target,noise,epoch)
        if step % 10 == 0:
          print( "EPOCH-[%s/%s]- LOSS:%.4f   (%s/%s) " % \
                    (epoch,epochs,disc_loss,step,steps_per_epoch))

    # with summary_writer.as_default():
    #   val_loss = tf.reduce_mean(val_losses)
    #   print( "EPOCH-[%s/%s]- GEN LOSS:%.4f , DISC LOSS:%.4f ,val_loss:%.4f" % \
    #                 (epoch,epochs,gen_loss,disc_loss,val_loss))
    #   tf.summary.scalar('val_loss', val_loss, step=epoch)


    # 保存一次模型
    if epoch % save_interval == 0:
      save_path = ckpt_manager.save()
      print("Saved checkpoint for epoch {}: {}".format(epoch, save_path))
      # chkfilename = "gan_checkpoints" \
      #       +"."+datetime.now().strftime("%Y%m%d_%H%M") \
      #       +( ".epoch-%s.ckpt" % epoch)
      # checkpoint_prefix = os.path.join(run_logdir, chkfilename)
      # checkpoint.save(file_prefix = checkpoint_prefix)

    # epoch end
    print ('Time for epoch {} is {:.2f} sec'.format(epoch + 1, time.time()-start))


# %%

from dataloader import fetch_image_label,create_dataset,create_dataset_in_mem
run_logdir = "/content/drive/My Drive/ugb"
val_dir = run_logdir+"/noise"
targets_dir = run_logdir+"/targets"
tg_imgs,tg_labels = fetch_image_label(targets_dir)
val_imgs,val_labels = fetch_image_label(val_dir,0)
X_train = create_dataset_in_mem(tg_imgs,tg_labels,True)#.batch(BATCH_SIZE)
X_val = create_dataset(val_imgs,val_labels)#.batch(BATCH_SIZE)

new_train = tf.data.Dataset.zip((X_train,X_val)).batch(BATCH_SIZE)

for (anchor,target,_),(noise,_) in new_train.take(1):
  imgs = zip(anchor,target,noise)
  plt.figure(figsize=(BATCH_SIZE,3))
  for index,imgrow in enumerate(imgs):
    for imc,im in enumerate(imgrow):
      plt.subplot(BATCH_SIZE,3,index*3+imc+1)
      plt.imshow(im,cmap="binary")
      plt.axis("off")

train(new_train,100,51)

def plot_multiple_images2(images, n_cols=None):
    n_cols = n_cols or len(images)
    n_rows = (len(images) - 1) // n_cols + 1
    # if images.shape[-1] == 1:
    #     images = np.squeeze(images, axis=-1)
    plt.figure(figsize=(n_cols, n_rows))
    for index, image in enumerate(images):
        plt.subplot(n_rows, n_cols, index + 1)
        plt.imshow(image, cmap="binary")
        plt.axis("off")

"""# eveluat"""

# %load_ext tensorboard
# %tensorboard --bind_all  --logdir=/content/drive/My\ Drive/ugb/v8_fit --port=6007

anchor_vecs = []
anchor_met = []

target_vecs = []
target_met = []

noise_vecs = []
noise_met =[]

for anchor,target,y in X_train.batch(BATCH_SIZE).take(10):
  anchor_vecs.append( discriminator(anchor, training=False) )
  anchor_met.append(y)

  target_vecs.append( discriminator(target, training=False) )
  target_met.append(y)

for noise,y in X_val.batch(BATCH_SIZE).take(10):
  noise_vecs.append( discriminator(noise, training=False) )
  noise_met.append(y)

vecs = tf.concat(anchor_vecs+target_vecs+noise_vecs,0)
mets = tf.concat(anchor_met+target_met+noise_met,0)
# np.savetxt("vecs.tsc",vecs,delimiter="\t")
# np.savetxt("met.tsc",mets,delimiter="\t")

vecs.shape,mets.shape

def pairwise_distance(feature, squared=False):
    """Computes the pairwise distance matrix with numerical stability.
    output[i, j] = || feature[i, :] - feature[j, :] ||_2
    Args:
      feature: 2-D Tensor of size [number of data, feature dimension].
      squared: Boolean, whether or not to square the pairwise distances.
    Returns:
      pairwise_distances: 2-D Tensor of size [number of data, number of data].
    """
    # yapf: disable
    pairwise_distances_squared = tf.math.add(
        tf.math.reduce_sum(
            tf.math.square(feature),
            axis=[1],
            keepdims=True),
        tf.math.reduce_sum(
            tf.math.square(tf.transpose(feature)),
            axis=[0],
            keepdims=True)) - 2.0 * tf.matmul(feature, tf.transpose(feature))
    # yapf: enable

    # Deal with numerical inaccuracies. Set small negatives to zero.
    pairwise_distances_squared = tf.math.maximum(pairwise_distances_squared,
                                                 0.0)
    # Get the mask where the zero distances are at.
    error_mask = tf.math.less_equal(pairwise_distances_squared, 0.0)

    # Optionally take the sqrt.
    if squared:
        pairwise_distances = pairwise_distances_squared
    else:
        pairwise_distances = tf.math.sqrt(
            pairwise_distances_squared +
            tf.cast(error_mask, dtype=tf.dtypes.float32) * 1e-16)

    # Undo conditionally adding 1e-16.
    pairwise_distances = tf.math.multiply(
        pairwise_distances,
        tf.cast(tf.math.logical_not(error_mask), dtype=tf.dtypes.float32))

    num_data = tf.shape(feature)[0]
    # Explicitly set diagonals to zero.
    mask_offdiagonals = tf.ones_like(pairwise_distances) - tf.linalg.diag(
        tf.ones([num_data]))
    pairwise_distances = tf.math.multiply(pairwise_distances,
                                          mask_offdiagonals)
    return pairwise_distances

pdis = pairwise_distance(vecs)

y_pred = []
for i in range(0,len(mets)):
  ind = tf.argsort(pdis[i,...])[1]
  y_pred.append(mets[ind])

from sklearn.metrics import confusion_matrix

cfm = confusion_matrix(mets,y_pred)
plt.matshow(cfm)
plt.show()

tf.one_hot(y_pred,16)

from sklearn.metrics import f1_score,accuracy_score

f1_score(mets,y_pred,average='macro'),accuracy_score(mets,y_pred)

def plot_confusion_matrix(cm,
                          target_names,
                          title='Confusion matrix',
                          cmap=None,
                          normalize=True):
    """
    given a sklearn confusion matrix (cm), make a nice plot

    Arguments
    ---------
    cm:           confusion matrix from sklearn.metrics.confusion_matrix

    target_names: given classification classes such as [0, 1, 2]
                  the class names, for example: ['high', 'medium', 'low']

    title:        the text to display at the top of the matrix

    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm
                  see http://matplotlib.org/examples/color/colormaps_reference.html
                  plt.get_cmap('jet') or plt.cm.Blues

    normalize:    If False, plot the raw numbers
                  If True, plot the proportions

    Usage
    -----
    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by
                                                              # sklearn.metrics.confusion_matrix
                          normalize    = True,                # show proportions
                          target_names = y_labels_vals,       # list of names of the classes
                          title        = best_estimator_name) # title of graph

    Citiation
    ---------
    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html

    """
    import matplotlib.pyplot as plt
    import numpy as np
    import itertools

    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names, rotation=45)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")


    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))
    plt.show()

plot_confusion_matrix(cfm,list(range(0,16)),normalize=False)

