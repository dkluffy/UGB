# -*- coding: utf-8 -*-
"""v6_softmax.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NqVkxJMu5pgsMvwHck0Zi8tDFhtZgPX4
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import os

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
from datetime import datetime
import time

from dataloader import fetch_image_label,create_dataset,create_dataset_in_mem,create_ds_temp
from tools import write_images_ds
import baseconf as bcf

from functools import partial

tf.config.list_physical_devices()

DefaultConv2D = partial(layers.Conv2D, kernel_size=3, strides=1,
                        padding="SAME", use_bias=False)

class ResidualUnit(layers.Layer):
    def __init__(self, filters, strides=1, activation="relu", **kwargs):
        super().__init__(**kwargs)
        self.activation = tf.keras.activations.get(activation)
        self.main_layers = [
            DefaultConv2D(filters, strides=strides),
            layers.BatchNormalization(),
            self.activation,
            DefaultConv2D(filters),
            layers.BatchNormalization()]
        self.skip_layers = []
        if strides > 1:
            self.skip_layers = [
                DefaultConv2D(filters, kernel_size=1, strides=strides),
                layers.BatchNormalization()]

    def call(self, inputs):
        Z = inputs
        for layer in self.main_layers:
            Z = layer(Z)
        skip_Z = inputs
        for layer in self.skip_layers:
            skip_Z = layer(skip_Z)
        return self.activation(Z + skip_Z)

    
def make_ResNet34():

    """
    Use ResNet34 instead of the orig

    """ 
    initializer = tf.keras.initializers.he_uniform()
    #CNN network
    inp = layers.Input(shape=[128, 128, 3], name='input_image')
    X = DefaultConv2D(64, kernel_size=7, strides=2)(inp)
    X = layers.BatchNormalization()(X)
    X = layers.Activation("relu")(X)
    X = layers.MaxPool2D(pool_size=3, strides=2, padding="SAME")(X)
    prev_filters = 64
    for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:
        strides = 1 if filters == prev_filters else 2
        X = ResidualUnit(filters, strides=strides)(X)
        prev_filters = filters
    X = layers.GlobalAvgPool2D()(X)
    x = layers.Flatten()(X)
    #x = layers.Dense(1024,activation='relu',kernel_initializer=initializer)(x)
    #x = layers.BatchNormalization()(x)
    last = layers.Dense(64,activation='softmax')(x)

    return tf.keras.Model(inputs=inp, outputs=last)

def model_transfer_learn(input_shape=bcf.TARGET_SHAPE):

    #Model file location: ~/.keras/models/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5
    #or from internet
    base_model = tf.keras.applications.ResNet50V2(input_shape=input_shape,
                                               include_top=False,
                                               weights='imagenet')
    
    # Freeze base_model weights
    base_model.trainable = True
    print("Number of layers in the base model: ", len(base_model.layers))
    base_model.summary()

    # Freeze all the layers before the `fine_tune_at` layer
    for layer in base_model.layers[:150]:
      layer.trainable =  False

    model = tf.keras.Sequential([
        base_model,
        layers.MaxPooling2D(),
        layers.Flatten(),
        layers.Dense(1024, activation='relu',kernel_initializer=initializer),
        #layers.Dropout(0.1),
        layers.Dense(64, activation='softmax',kernel_initializer=initializer)
    ])

    return model


discriminator = make_ResNet34()
#discriminator = model_transfer_learn()
discriminator.summary()

###################HParams##############################
BATCH_SIZE=8
noise_dim=512
base_learning_rate=0.01
save_interval=5
# Optimizers
# generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
# discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

#generator_optimizer = tf.keras.optimizers.Adam()
discriminator_optimizer = tf.keras.optimizers.SGD(base_learning_rate,0.1)
#discriminator_optimizer = tf.keras.optimizers.Adadelta()
# lr callback
def lr_scheduler(epoch):
  learning_rate = base_learning_rate
  if epoch > 10:
    learning_rate =base_learning_rate/2
  if epoch > 20:
    learning_rate = base_learning_rate/10
  if epoch > 30:
    learning_rate = base_learning_rate * tf.math.exp(0.1 * (10 - epoch))
  #for tensorboard
  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)
  print("current lr:",learning_rate)
  return learning_rate

LAMBDA = 10

#tb callback
run_logdir = "/content/drive/My Drive/ugb"
version = "/v6"

##############################################################################



# softmax loss
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
def discriminator_loss(y_true,y_pred):
  return loss_object(y_true,y_pred)

# checkpoint and fitlog
checkpoint = tf.train.Checkpoint(discriminator=discriminator)
ckpt_manager = tf.train.CheckpointManager(checkpoint, run_logdir+version, max_to_keep=3)

fit_log = os.path.join(run_logdir+version+"_fit",datetime.now().strftime("%Y%m%d-%H%M%S"))
print("fit_log:",fit_log)
summary_writer = tf.summary.create_file_writer(fit_log)

# single train step
@tf.function
def train_step(target,y_true, epoch):

  with tf.GradientTape() as disc_tape:
 
    y_pred = discriminator(target, training=True)
    disc_loss = discriminator_loss(y_true, y_pred)

  discriminator_gradients = disc_tape.gradient(disc_loss,
                                               discriminator.trainable_variables)

  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,
                                              discriminator.trainable_variables))

  with summary_writer.as_default():
    tf.summary.scalar('disc_loss', disc_loss, step=epoch)
  return disc_loss
# def generate_and_save_images(model, epoch, test_input):
#     # 注意 training` 设定为 False
#     # 因此，所有层都在推理模式下运行（batchnorm）。
#     #predictions = model(test_input, training=False)
#     #write_images_tb(predictions)

val_metric = tf.keras.metrics.SparseCategoricalAccuracy()
def eveluator(x,y_true):
  """
  这里只测试，目标图片（随机变换）和真实随机噪声（即不包含目标的图片）
  """
  result = discriminator(x, training=False)
  ev_loss = loss_object(y_true,result)
  val_metric.update_state(y_true,result)
  return ev_loss,val_metric.result().numpy()

def train(X_train,X_noise,X_val,epochs,init_epoch=1,steps_per_epoch=100,val_steps=10):
  """
  X_train - ds: 只包含目标图片
  X_val - ds: 只包含noise
  """
  checkpoint.restore(ckpt_manager.latest_checkpoint)
  if ckpt_manager.latest_checkpoint:
    print("Restored from {}".format(ckpt_manager.latest_checkpoint))
  else:
    print("Initializing from scratch.")
  
  print("Fire to Train....")
  
  for epoch in range(init_epoch,epochs+1):
    
    start = time.time()
    #discriminator_optimizer = tf.keras.optimizers.Adam(lr_scheduler(epoch))
    
    for step in range(1,steps_per_epoch+1):          
      for x,y in X_train.take(1):
        disc_loss = train_step(x,y,epoch)
        if step % 25 == 0:
          print( "EPOCH-[%s/%s]- DISC LOSS:%.4f (%s/%s) " % \
                    (epoch,epochs,disc_loss,step,steps_per_epoch))
      # for x,y in X_noise.take(1):
      #   disc_loss = train_step(x,y,epoch)
      #   if step % 50 == 0:
      #     print( "noise::>> EPOCH-[%s/%s]- DISC LOSS:%.4f (%s/%s) " % \
      #               (epoch,epochs,disc_loss,step,steps_per_epoch))
    # eva
    for x,y in X_val.take(1):
      val_loss,val_acc = eveluator(x,y)
      print( "EPOCH-[%s/%s]-  DISC LOSS:%.4f ,val_loss:%.4f,acc:%.4f , (%s/%s) " % \
                    (epoch,epochs,disc_loss,val_loss,val_acc,step,steps_per_epoch))
    with summary_writer.as_default():
      tf.summary.scalar('val_loss', val_loss, step=epoch)
      tf.summary.scalar('val_acc', val_acc, step=epoch)

    # 保存一次模型
    if epoch % save_interval == 0:
      save_path = ckpt_manager.save()
      print("Saved checkpoint for epoch {}: {}".format(epoch, save_path))
      # chkfilename = "gan_checkpoints" \
      #       +"."+datetime.now().strftime("%Y%m%d_%H%M") \
      #       +( ".epoch-%s.ckpt" % epoch)
      # checkpoint_prefix = os.path.join(run_logdir, chkfilename)
      # checkpoint.save(file_prefix = checkpoint_prefix)

    # epoch end
    print ('Time for epoch {} is {:.2f} sec'.format(epoch, time.time()-start))


# %%

val_dir = run_logdir+"/noise"
targets_dir = run_logdir+"/targets"
tg_imgs,tg_labels = fetch_image_label(targets_dir)
noise_imgs,noise_labels = fetch_image_label(val_dir,0)
X_train = create_dataset_in_mem(tg_imgs,tg_labels)#.batch(BATCH_SIZE)
X_val = create_ds_temp(tg_imgs,tg_labels).batch(BATCH_SIZE)
X_noise = create_dataset(noise_imgs,noise_labels)#.batch(BATCH_SIZE)

# new_train = X_train.concatenate(X_noise) - 不起作用
new_val = tf.data.experimental.sample_from_datasets([X_train,X_noise],[0.9,0.1]).batch(BATCH_SIZE)
new_train = X_train.batch(BATCH_SIZE)

from vizer import plot_multiple_images

for x,y in new_train.take(2):
  print(y)
  plot_multiple_images(x,4)

train(new_train,X_noise,X_val,100,1,200,20)

#checkpoint.restore(ckpt_manager.latest_checkpoint)

# X_val2 = tf.data.Dataset.zip((X_train,X_noise))
# for t,n in X_val2.take(10):
#   tx,ty = t
#   nx,ny = n
#   x = tf.concat([tx,nx],0)
#   y_true = tf.concat([ty,ny],0)
#   y_pred = discriminator(x,training=False)
#   val_metric.update_state(y_true,y_pred)
#   print(val_metric.result().numpy())

for x,y_true in X_val.take(10):
  plot_multiple_images(x)
  y_pred = discriminator(x,training=False)
  val_metric.update_state(y_true,y_pred)
  lb = y_pred.numpy()
  lb[lb<0.7]=0
  lb = [np.argmax(b) for b in lb]
  print(y_true,lb,val_metric.result().numpy())

for x,y_true in new_val.take(10):
  plot_multiple_images(x)
  y_pred = discriminator(x,training=False)
  val_metric.update_state(y_true,y_pred)
  lb = y_pred.numpy()
  lb[lb<0.7]=0
  lb = [np.argmax(b) for b in lb]
  print(y_true.numpy(),lb,val_metric.result().numpy())

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard
# %load_ext tensorboard
# %tensorboard --bind_all  --logdir=/content/drive/My\ Drive/ugb/v6_fit --port=6007

#!tar czf /content/drive/My\ Drive/ugb/v5/v5.60epoch.tar.gz /content/drive/My\ Drive/ugb/v5/checkpoint /content/drive/My\ Drive/ugb/v5/ckpt-14.*